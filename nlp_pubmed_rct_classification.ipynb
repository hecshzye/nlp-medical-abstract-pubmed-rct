{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp-pubmed-rct-classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1TGU5mtAosYsHxXnaw9_uAP91Pg9czPX1",
      "authorship_tag": "ABX9TyMcEkhjWFFE2T5ZwxzZ+a/X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hecshzye/nlp-medical-abstract-pubmed-rct/blob/main/nlp_pubmed_rct_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Medical Abstract Classification using Natural Language Processing"
      ],
      "metadata": {
        "id": "Uq_ssycxR8Ar"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The objective is to build a deep learning model which makes medical research paper abstract easier to read.\n",
        "  - Dataset used in this project is the `PubMed 200k RCT Dataset for Sequential Sentence Classification in Medical Abstract by Cornell University`: https://arxiv.org/abs/1710.06071\n",
        "  - The initial deep learning research paper was built with the PubMed 200k RCT.\n",
        "  - Dataset has about `200,000 labelled Randomized Control Trial abstracts`.\n",
        "  - The goal of the project was build NLP models with the dataset to classify sentences in sequential order."
      ],
      "metadata": {
        "id": "bOGykK3Ad-wp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " - As the RCT research papers with unstructured abstracts slows down researchers navigating the literature. \n",
        " - The unstructured abstracts are sometimes hard to read and understand especially when it can disrupt time management and deadlines.\n",
        " - This NLP model can classify the abstract sentences into its respective roles:\n",
        "    - Such as `Objective`, `Methods`, `Results` and `Conclusions`.\n",
        "    "
      ],
      "metadata": {
        "id": "RgYVNMflgo86"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The PubMed 200k RCT Dataset - https://github.com/Franck-Dernoncourt/pubmed-rct"
      ],
      "metadata": {
        "id": "1Lmr_h4FipFw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Similar projects using the dataset:\n",
        "   - Claim Extraction for Scientific Publications 2018: https://github.com/titipata/detecting-scientific-claim"
      ],
      "metadata": {
        "id": "N2d_bTBIi6of"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Abstract** \n",
        "\n",
        "PubMed 200k RCT is new dataset based on PubMed for sequential sentence classification. The dataset consists of approximately 200,000 abstracts of randomized controlled trials, totaling 2.3 million sentences. Each sentence of each abstract is labeled with their role in the abstract using one of the following classes: background, objective, method, result, or conclusion. The purpose of releasing this dataset is twofold. First, the majority of datasets for sequential short-text classification (i.e., classification of short texts that appear in sequences) are small: we hope that releasing a new large dataset will help develop more accurate algorithms for this task. Second, from an application perspective, researchers need better tools to efficiently skim through the literature. Automatically classifying each sentence in an abstract would help researchers read abstracts more efficiently, especially in fields where abstracts may be long, such as the medical field."
      ],
      "metadata": {
        "id": "WXb2Qlu8k2Fk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Dictionary**\n",
        "\n",
        "- `PubMed 20k` is a subset of `PubMed 200k`. I.e., any abstract present in `PubMed 20k` is also present in `PubMed 200k`.\n",
        "- `PubMed_200k_RCT` is the same as `PubMed_200k_RCT_numbers_replaced_with_at_sign`, except that in the latter all numbers had been replaced by `@`. (same for `PubMed_20k_RCT` vs. `PubMed_20k_RCT_numbers_replaced_with_at_sign``).\n",
        "- Since Github file size limit is 100 MiB, we had to compress `PubMed_200k_RCT\\train.7z` and `PubMed_200k_RCT_numbers_replaced_with_at_sign\\train.zip`. \n",
        "- To uncompress `train.7z`, you may use `7-Zip` on Windows, `Keka` on Mac OS X, or `p7zip` on Linux."
      ],
      "metadata": {
        "id": "MvAjGdF0lACB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing data and EDA"
      ],
      "metadata": {
        "id": "T1JweqbejVX4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Franck-Dernoncourt/pubmed-rct.git\n",
        "!ls pubmed-rct"
      ],
      "metadata": {
        "id": "zM12MSlAnKCo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d08000f4-f96f-494a-ef56-642c5f030da8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pubmed-rct'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 33 (delta 0), reused 0 (delta 0), pack-reused 30\u001b[K\n",
            "Unpacking objects: 100% (33/33), done.\n",
            "PubMed_200k_RCT\n",
            "PubMed_200k_RCT_numbers_replaced_with_at_sign\n",
            "PubMed_20k_RCT\n",
            "PubMed_20k_RCT_numbers_replaced_with_at_sign\n",
            "README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initial Data exploration and modelling with PubMed_20k dataset"
      ],
      "metadata": {
        "id": "FFpPwS_SqS48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3mLk-7tqk3K",
        "outputId": "e27e2ca5-6682-463e-8fae-f088775bcd80"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dev.txt  test.txt  train.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import random\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "TZiWPqoaqzBL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# functions pre-written for workflow\n",
        "!wget https://raw.githubusercontent.com/hecshzye/nlp-medical-abstract-pubmed-rct/main/helper_functions.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRZJgoCeFBsX",
        "outputId": "aff9ce7a-0254-44e9-8e02-2858ed0bfe18"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-16 08:59:32--  https://raw.githubusercontent.com/hecshzye/nlp-medical-abstract-pubmed-rct/main/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6442 (6.3K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]   6.29K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-01-16 08:59:32 (72.0 MB/s) - ‘helper_functions.py’ saved [6442/6442]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import create_tensorboard_callback, calculate_results, plot_loss_curves"
      ],
      "metadata": {
        "id": "i6KrTZnaFKtu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for reading the document\n",
        "def get_doc(filename):\n",
        "  with open(filename, \"r\") as f:\n",
        "    return f.readlines()"
      ],
      "metadata": {
        "id": "JMifgqkxsC5w"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/\"\n",
        "filenames = [data_dir + filename for filename in os.listdir(data_dir)]\n",
        "filenames"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGZi11CDrVxa",
        "outputId": "6a475a12-a1a3-484c-f938-b3d13406b9a8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt',\n",
              " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt',\n",
              " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing \n",
        "train_lines = get_doc(data_dir+\"train.txt\")\n",
        "train_lines[:30]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZBDfw7gsX-8",
        "outputId": "532320c7-85ff-4d66-9df5-c4a2f26cdc5f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['###24293578\\n',\n",
              " 'OBJECTIVE\\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n',\n",
              " 'METHODS\\tA total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .\\n',\n",
              " 'METHODS\\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\\n',\n",
              " 'METHODS\\tPain was assessed using the visual analog pain scale ( @-@ mm ) .\\n',\n",
              " 'METHODS\\tSecondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .\\n',\n",
              " 'METHODS\\tSerum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .\\n',\n",
              " 'RESULTS\\tThere was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .\\n',\n",
              " 'RESULTS\\tThe mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .\\n',\n",
              " 'RESULTS\\tFurther , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .\\n',\n",
              " 'RESULTS\\tThese differences remained significant at @ weeks .\\n',\n",
              " 'RESULTS\\tThe Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .\\n',\n",
              " 'CONCLUSIONS\\tLow-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ) .\\n',\n",
              " '\\n',\n",
              " '###24854809\\n',\n",
              " 'BACKGROUND\\tEmotional eating is associated with overeating and the development of obesity .\\n',\n",
              " 'BACKGROUND\\tYet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .\\n',\n",
              " 'OBJECTIVE\\tThe aim of this study was to test if attention bias for food moderates the effect of self-reported emotional eating during sad mood ( vs neutral mood ) on actual food intake .\\n',\n",
              " 'OBJECTIVE\\tIt was expected that emotional eating is predictive of elevated attention for food and higher food intake after an experimentally induced sad mood and that attentional maintenance on food predicts food intake during a sad versus a neutral mood .\\n',\n",
              " 'METHODS\\tParticipants ( N = @ ) were randomly assigned to one of the two experimental mood induction conditions ( sad/neutral ) .\\n',\n",
              " 'METHODS\\tAttentional biases for high caloric foods were measured by eye tracking during a visual probe task with pictorial food and neutral stimuli .\\n',\n",
              " 'METHODS\\tSelf-reported emotional eating was assessed with the Dutch Eating Behavior Questionnaire ( DEBQ ) and ad libitum food intake was tested by a disguised food offer .\\n',\n",
              " 'RESULTS\\tHierarchical multivariate regression modeling showed that self-reported emotional eating did not account for changes in attention allocation for food or food intake in either condition .\\n',\n",
              " 'RESULTS\\tYet , attention maintenance on food cues was significantly related to increased intake specifically in the neutral condition , but not in the sad mood condition .\\n',\n",
              " 'CONCLUSIONS\\tThe current findings show that self-reported emotional eating ( based on the DEBQ ) might not validly predict who overeats when sad , at least not in a laboratory setting with healthy women .\\n',\n",
              " 'CONCLUSIONS\\tResults further suggest that attention maintenance on food relates to eating motivation when in a neutral affective state , and might therefore be a cognitive mechanism contributing to increased food intake in general , but maybe not during sad mood .\\n',\n",
              " '\\n',\n",
              " '###25165090\\n',\n",
              " 'BACKGROUND\\tAlthough working smoke alarms halve deaths in residential fires , many households do not keep alarms operational .\\n',\n",
              " 'BACKGROUND\\tWe tested whether theory-based education increases alarm operability .\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Data dictionary**\n",
        "\n",
        "`\\t` = tab seperator\n",
        "\n",
        "`\\n` = new line\n",
        "\n",
        "`###` = abstract ID\n",
        "\n",
        "`\"line_number\"` = line position\n",
        "\n",
        "`\"text\"` = text line\n",
        "\n",
        "`\"total_lines\"` = total number of lines in one abstract\n",
        "\n",
        "`\"target\"` = objective of the abstract\n",
        "\n"
      ],
      "metadata": {
        "id": "6ZOKbxQAsyNT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for preprocessing the data\n",
        "\n",
        "def preprocessing_text_with_line_number(filename):\n",
        "  input_lines = get_doc(filename)\n",
        "  abstract_lines = \"\"\n",
        "  abstract_samples = []\n",
        "\n",
        "  for line in input_lines:\n",
        "    if line.startswith(\"###\"):\n",
        "      abstract_id = line\n",
        "      abstract_lines = \"\"\n",
        "    elif line.isspace():\n",
        "      abstract_line_split = abstract_lines.splitlines()\n",
        "       \n",
        "      for abstract_line_number, abstract_line in enumerate(abstract_line_split):\n",
        "        line_data = {}\n",
        "        target_text_split = abstract_line.split(\"\\t\")\n",
        "        line_data[\"target\"] = target_text_split[0]\n",
        "        line_data[\"text\"] = target_text_split[1].lower()\n",
        "        line_data[\"line_number\"] = abstract_line_number\n",
        "        line_data[\"total_lines\"] = len(abstract_line_split) - 1\n",
        "        abstract_samples.append(line_data)\n",
        "\n",
        "    else:\n",
        "      abstract_lines += line \n",
        "  return abstract_samples    "
      ],
      "metadata": {
        "id": "AEl-XZPQttN7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting data using the function\n",
        "train_samples = preprocessing_text_with_line_number(data_dir + \"train.txt\")\n",
        "val_samples = preprocessing_text_with_line_number(data_dir + \"dev.txt\")\n",
        "test_samples = preprocessing_text_with_line_number(data_dir + \"test.txt\")\n",
        "len(train_samples), len(test_samples), len(val_samples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCD9DYIU17GH",
        "outputId": "a8623bb2-3e14-4017-8dae-e4920507eb67"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(180040, 30135, 30212)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_samples[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hacxnrvq2r7n",
        "outputId": "3a228ef6-1363-4210-92eb-aaeb1ef710ed"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'line_number': 0,\n",
              "  'target': 'OBJECTIVE',\n",
              "  'text': 'to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 1,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 2,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 3,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 4,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 5,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 6,\n",
              "  'target': 'RESULTS',\n",
              "  'text': 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 7,\n",
              "  'target': 'RESULTS',\n",
              "  'text': 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 8,\n",
              "  'target': 'RESULTS',\n",
              "  'text': 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 9,\n",
              "  'target': 'RESULTS',\n",
              "  'text': 'these differences remained significant at @ weeks .',\n",
              "  'total_lines': 11}]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a DataFrame\n",
        "train_df = pd.DataFrame(train_samples)\n",
        "val_df = pd.DataFrame(val_samples)\n",
        "test_df = pd.DataFrame(test_samples)\n",
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "gEQRm8jZ40lD",
        "outputId": "9ee2064c-611a-4404-ed52-64b567808748"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-31b54410-e7ed-473d-83a0-2c82f75c72d1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "      <th>line_number</th>\n",
              "      <th>total_lines</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OBJECTIVE</td>\n",
              "      <td>to investigate the efficacy of @ weeks of dail...</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>a total of @ patients with primary knee oa wer...</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>outcome measures included pain reduction and i...</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>pain was assessed using the visual analog pain...</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>secondary outcome measures included the wester...</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-31b54410-e7ed-473d-83a0-2c82f75c72d1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-31b54410-e7ed-473d-83a0-2c82f75c72d1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-31b54410-e7ed-473d-83a0-2c82f75c72d1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      target  ... total_lines\n",
              "0  OBJECTIVE  ...          11\n",
              "1    METHODS  ...          11\n",
              "2    METHODS  ...          11\n",
              "3    METHODS  ...          11\n",
              "4    METHODS  ...          11\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.target.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAydvGtt7lHx",
        "outputId": "7218966f-f487-485e-db27-22719884edc4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "METHODS        59353\n",
              "RESULTS        57953\n",
              "CONCLUSIONS    27168\n",
              "BACKGROUND     21727\n",
              "OBJECTIVE      13839\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.total_lines.plot.hist();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "GHq-mW6b7tet",
        "outputId": "89e1273a-7c4e-4438-f322-23dadbbdac19"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAD6CAYAAABgZXp6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAXpUlEQVR4nO3df7BfdX3n8efLRCpSkVDSLJNgg21Gl7r+gCvg1HatjCHg1tBdl4WtS5ZhiDNgV8f9QXQ6i8Uyk+5spdJatqlkTVwV8SfZEppGxHb7Bz+CIAjo5IqwJAJJDRDRFhZ97x/fz5Wv4ebyzbn53i/35vmY+c49530+55zPZ74TXpxzPt/vN1WFJEldvGjUHZAkzV6GiCSpM0NEktSZISJJ6swQkSR1ZohIkjobWogkeVWSO/tee5O8L8nRSbYm2d7+Lmjtk+TKJONJ7kpyYt+xVrX225Os6quflOTuts+VSTKs8UiSnisz8TmRJPOAncApwMXAnqpam2QNsKCqLklyJvC7wJmt3Uer6pQkRwPbgDGggNuBk6rqsSS3Av8BuAXYDFxZVTdM1Zdjjjmmli5dOpRxStJcdPvtt/99VS2cbNv8GerDacB3qurBJCuBt7T6BuBrwCXASmBj9VLt5iRHJTm2td1aVXsAkmwFViT5GnBkVd3c6huBs4ApQ2Tp0qVs27bt4I5OkuawJA/ub9tMPRM5B/hMW15UVQ+35UeARW15MfBQ3z47Wm2q+o5J6pKkGTL0EElyGPAO4HP7bmtXHUO/n5ZkdZJtSbbt3r172KeTpEPGTFyJnAF8vaoebeuPtttUtL+7Wn0ncFzffktabar6kknqz1FV66pqrKrGFi6c9LaeJKmDmQiRc3n2VhbAJmBihtUq4Lq++nltltapwBPtttcWYHmSBW0m13JgS9u2N8mpbVbWeX3HkiTNgKE+WE9yBPA24N195bXAtUkuAB4Ezm71zfRmZo0DPwLOB6iqPUk+DNzW2l028ZAduAj4BHA4vQfqUz5UlyQdXDMyxfeFZGxsrJydJUmDS3J7VY1Nts1PrEuSOjNEJEmdGSKSpM5m6hPrmqWWrrl+JOd9YO3bR3JeSQfGKxFJUmeGiCSpM0NEktSZISJJ6swQkSR1ZohIkjozRCRJnRkikqTODBFJUmeGiCSpM0NEktSZISJJ6swQkSR1ZohIkjozRCRJnRkikqTODBFJUmeGiCSps6GGSJKjknw+ybeS3JfkTUmOTrI1yfb2d0FrmyRXJhlPcleSE/uOs6q1355kVV/9pCR3t32uTJJhjkeS9LOGfSXyUeCvqurVwOuA+4A1wI1VtQy4sa0DnAEsa6/VwFUASY4GLgVOAU4GLp0Intbmwr79Vgx5PJKkPkMLkSQvB34DuBqgqp6uqseBlcCG1mwDcFZbXglsrJ6bgaOSHAucDmytqj1V9RiwFVjRth1ZVTdXVQEb+44lSZoBw7wSOR7YDfzPJHck+XiSI4BFVfVwa/MIsKgtLwYe6tt/R6tNVd8xSV2SNEOGGSLzgROBq6rqDcAPefbWFQDtCqKG2AcAkqxOsi3Jtt27dw/7dJJ0yBhmiOwAdlTVLW398/RC5dF2K4r2d1fbvhM4rm//Ja02VX3JJPXnqKp1VTVWVWMLFy6c1qAkSc8aWohU1SPAQ0le1UqnAfcCm4CJGVargOva8ibgvDZL61TgiXbbawuwPMmC9kB9ObClbdub5NQ2K+u8vmNJkmbA/CEf/3eBTyU5DLgfOJ9ecF2b5ALgQeDs1nYzcCYwDvyotaWq9iT5MHBba3dZVe1pyxcBnwAOB25oL0nSDBlqiFTVncDYJJtOm6RtARfv5zjrgfWT1LcBr5lmNyVJHfmJdUlSZ4aIJKkzQ0SS1JkhIknqzBCRJHVmiEiSOjNEJEmdGSKSpM4MEUlSZ4aIJKkzQ0SS1JkhIknqzBCRJHVmiEiSOjNEJEmdGSKSpM4MEUlSZ4aIJKkzQ0SS1JkhIknqzBCRJHVmiEiSOhtqiCR5IMndSe5Msq3Vjk6yNcn29ndBqyfJlUnGk9yV5MS+46xq7bcnWdVXP6kdf7ztm2GOR5L0s2biSuQ3q+r1VTXW1tcAN1bVMuDGtg5wBrCsvVYDV0EvdIBLgVOAk4FLJ4Kntbmwb78Vwx+OJGnCKG5nrQQ2tOUNwFl99Y3VczNwVJJjgdOBrVW1p6oeA7YCK9q2I6vq5qoqYGPfsSRJM2DYIVLAXye5PcnqVltUVQ+35UeARW15MfBQ3747Wm2q+o5J6s+RZHWSbUm27d69ezrjkST1mT/k47+5qnYm+UVga5Jv9W+sqkpSQ+4DVbUOWAcwNjY29PNJ0qFiqFciVbWz/d0FfIneM41H260o2t9drflO4Li+3Ze02lT1JZPUJUkzZGghkuSIJC+bWAaWA98ENgETM6xWAde15U3AeW2W1qnAE+221xZgeZIF7YH6cmBL27Y3yaltVtZ5fceSJM2AYd7OWgR8qc26nQ98uqr+KsltwLVJLgAeBM5u7TcDZwLjwI+A8wGqak+SDwO3tXaXVdWetnwR8AngcOCG9pIkzZChhUhV3Q+8bpL694HTJqkXcPF+jrUeWD9JfRvwmml3VpLUiZ9YlyR1ZohIkjozRCRJnRkikqTODBFJUmeGiCSpM0NEktSZISJJ6swQkSR1ZohIkjozRCRJnRkikqTODBFJUmeGiCSpM0NEktTZQCGS5J8NuyOSpNln0CuRP0tya5KLkrx8qD2SJM0aA4VIVf068DvAccDtST6d5G1D7Zkk6QVv4GciVbUd+D3gEuCfA1cm+VaSfzmszkmSXtgGfSby2iRXAPcBbwV+q6r+aVu+Yoj9kyS9gM0fsN2fAB8HPlhV/zBRrKrvJfm9ofRMkvSCN+jtrLcDn54IkCQvSvJSgKr65FQ7JpmX5I4kf9nWj09yS5LxJJ9Nclir/1xbH2/bl/Yd4wOt/u0kp/fVV7TaeJI1BzJwSdL0DRoiXwEO71t/aasN4r30boNN+EPgiqr6FeAx4IJWvwB4rNWvaO1IcgJwDvCrwAp6M8XmJZkHfAw4AzgBOLe1lSTNkEFvZ72kqp6cWKmqJyeuRKaSZAm9q5jLgfcnCb3nKP+2NdkAfAi4CljZlgE+D/xpa78SuKaqngK+m2QcOLm1G6+q+9u5rmlt7x1wTHoBW7rm+pGd+4G1bx/ZuaXZZtArkR8mOXFiJclJwD9M0X7CHwP/BfhJW/8F4PGqeqat7wAWt+XFwEMAbfsTrf1P6/vss7+6JGmGDHol8j7gc0m+BwT4J8C/mWqHJP8C2FVVtyd5y7R6OU1JVgOrAV7xileMsiuSNKcMFCJVdVuSVwOvaqVvV9X/e57dfg14R5IzgZcARwIfBY5KMr9dbSwBdrb2O+l9mHFHkvnAy4Hv99Un9O+zv/q+/V8HrAMYGxur5+m3JGlAB/IFjG8EXgucSO8h9nlTNa6qD1TVkqpaSu/B+Fer6neAm4B3tmargOva8qa2Ttv+1aqqVj+nzd46HlgG3ArcBixrs70Oa+fYdADjkSRN00BXIkk+CfwycCfw41YuYGOHc14CXJPkD4A7gKtb/Wrgk+3B+R56oUBV3ZPkWnoPzJ8BLq6qH7d+vQfYAswD1lfVPR36I0nqaNBnImPACe3K4IBV1deAr7Xl+3l2dlV/m38E/vV+9r+c3gyvfeubgc1d+iRJmr5Bb2d9k97DdEmSfmrQK5FjgHuT3Ao8NVGsqncMpVeSpFlh0BD50DA7IUmanQad4vs3SX4JWFZVX2mfVp833K5Jkl7oBv0q+AvpfRXJn7fSYuDLw+qUJGl2GPTB+sX0Pjy4F376A1W/OKxOSZJmh0FD5KmqenpipX2i3E9+S9IhbtAQ+ZskHwQOb7+t/jngfw+vW5Kk2WDQEFkD7AbuBt5N7wN+/qKhJB3iBp2d9RPgL9pLkiRg8O/O+i6TPAOpqlce9B5JkmaNA/nurAkvofcdV0cf/O5IkmaTgZ6JVNX3+147q+qP6f3srSTpEDbo7awT+1ZfRO/KZNCrGEnSHDVoEPxR3/IzwAPA2Qe9N5KkWWXQ2Vm/OeyOSJJmn0FvZ71/qu1V9ZGD0x1J0mxyILOz3sizv2H+W/R+53z7MDoljdLSNdeP5LwPrHWuimafQUNkCXBiVf0AIMmHgOur6l3D6pgk6YVv0K89WQQ83bf+dKtJkg5hg16JbARuTfKltn4WsGE4XZIkzRaDzs66PMkNwK+30vlVdcfwuiVJmg0GvZ0F8FJgb1V9FNiR5PipGid5SZJbk3wjyT1Jfr/Vj09yS5LxJJ9Nclir/1xbH2/bl/Yd6wOt/u0kp/fVV7TaeJI1BzAWSdJBMOjP414KXAJ8oJVeDPyv59ntKeCtVfU64PXAiiSnAn8IXFFVvwI8BlzQ2l8APNbqV7R2JDkBOAf4VWAF8GdJ5iWZB3wMOAM4ATi3tZUkzZBBr0R+G3gH8EOAqvoe8LKpdqieJ9vqi9urgLfS+7126D1XOastr+TZ5yyfB05Lkla/pqqeqqrvAuPAye01XlX3t19dvKa1lSTNkEFD5OmqKtrXwSc5YpCd2hXDncAuYCvwHeDxqnqmNdkBLG7Li4GHANr2J4Bf6K/vs8/+6pKkGTJoiFyb5M+Bo5JcCHyFAX6gqqp+XFWvp/c5k5OBV3fu6TQkWZ1kW5Jtu3fvHkUXJGlOet7ZWe2W0mfpBcBe4FXAf62qrYOepKoeT3IT8CZ6QTS/XW0sAXa2ZjuB4+g9tJ8PvBz4fl99Qv8++6vve/51wDqAsbGx5/y4liSpm+e9Emm3sTZX1daq+s9V9Z8GCZAkC5Mc1ZYPB94G3AfcBLyzNVsFXNeWN7V12vavtnNvAs5ps7eOB5bR+8qV24BlbbbXYfQevk98LYskaQYM+mHDryd5Y1XddgDHPhbY0GZRvQi4tqr+Msm9wDVJ/gC4A7i6tb8a+GSScWAPvVCgqu5Jci1wL72vob+4qn4MkOQ9wBZgHrC+qu45gP5JkqZp0BA5BXhXkgfozdAKvYuU1+5vh6q6C3jDJPX76T0f2bf+j/R+dneyY10OXD5JfTOwebAhSJIOtilDJMkrqur/AqdP1U6SdGh6viuRL9P79t4Hk3yhqv7VTHRKkjQ7PN+D9fQtv3KYHZEkzT7PFyK1n2VJkp73dtbrkuyld0VyeFuGZx+sHznU3kmSXtCmDJGqmjdTHZEkzT4H8lXwkiT9DENEktSZISJJ6swQkSR1ZohIkjozRCRJnRkikqTODBFJUmeGiCSpM0NEktTZoD9KpRFauub6UXdBkibllYgkqTNDRJLUmSEiSerMEJEkdWaISJI6G1qIJDkuyU1J7k1yT5L3tvrRSbYm2d7+Lmj1JLkyyXiSu5Kc2HesVa399iSr+uonJbm77XNlkjy3J5KkYRnmlcgzwH+sqhOAU4GLk5wArAFurKplwI1tHeAMYFl7rQaugl7oAJcCpwAnA5dOBE9rc2HffiuGOB5J0j6GFiJV9XBVfb0t/wC4D1gMrAQ2tGYbgLPa8kpgY/XcDByV5FjgdGBrVe2pqseArcCKtu3Iqrq5qgrY2HcsSdIMmJFnIkmWAm8AbgEWVdXDbdMjwKK2vBh4qG+3Ha02VX3HJPXJzr86ybYk23bv3j2tsUiSnjX0EEny88AXgPdV1d7+be0Koobdh6paV1VjVTW2cOHCYZ9Okg4ZQw2RJC+mFyCfqqovtvKj7VYU7e+uVt8JHNe3+5JWm6q+ZJK6JGmGDHN2VoCrgfuq6iN9mzYBEzOsVgHX9dXPa7O0TgWeaLe9tgDLkyxoD9SXA1vatr1JTm3nOq/vWJKkGTDML2D8NeDfAXcnubPVPgisBa5NcgHwIHB227YZOBMYB34EnA9QVXuSfBi4rbW7rKr2tOWLgE8AhwM3tJckaYYMLUSq6u+A/X1u47RJ2hdw8X6OtR5YP0l9G/CaaXRTkjQNfmJdktSZISJJ6swQkSR1ZohIkjozRCRJnRkikqTODBFJUmeGiCSpM0NEktSZISJJ6swQkSR1ZohIkjozRCRJnRkikqTODBFJUmeGiCSpM0NEktSZISJJ6swQkSR1ZohIkjozRCRJnQ0tRJKsT7IryTf7akcn2Zpke/u7oNWT5Mok40nuSnJi3z6rWvvtSVb11U9Kcnfb58okGdZYJEmTmz/EY38C+FNgY19tDXBjVa1NsqatXwKcASxrr1OAq4BTkhwNXAqMAQXcnmRTVT3W2lwI3AJsBlYANwxxPNJQLV1z/UjO+8Dat4/kvJobhnYlUlV/C+zZp7wS2NCWNwBn9dU3Vs/NwFFJjgVOB7ZW1Z4WHFuBFW3bkVV1c1UVvaA6C0nSjJrpZyKLqurhtvwIsKgtLwYe6mu3o9Wmqu+YpC5JmkEje7DeriBqJs6VZHWSbUm27d69eyZOKUmHhJkOkUfbrSja312tvhM4rq/dklabqr5kkvqkqmpdVY1V1djChQunPQhJUs9Mh8gmYGKG1Srgur76eW2W1qnAE+221xZgeZIFbSbXcmBL27Y3yaltVtZ5fceSJM2Qoc3OSvIZ4C3AMUl20JtltRa4NskFwIPA2a35ZuBMYBz4EXA+QFXtSfJh4LbW7rKqmnhYfxG9GWCH05uV5cwsSZphQwuRqjp3P5tOm6RtARfv5zjrgfWT1LcBr5lOHyVJ0+Mn1iVJnRkikqTODBFJUmeGiCSpM0NEktSZISJJ6swQkSR1ZohIkjozRCRJnRkikqTODBFJUmeGiCSpM0NEktSZISJJ6swQkSR1ZohIkjozRCRJnRkikqTODBFJUmeGiCSps/mj7oCk0Vq65vqRnfuBtW8f2bl1cHglIknqbNZfiSRZAXwUmAd8vKrWDutco/w/NmkuGtW/Ka+ADp5ZfSWSZB7wMeAM4ATg3CQnjLZXknTomNUhApwMjFfV/VX1NHANsHLEfZKkQ8Zsv521GHiob30HcMqI+iJplnAywcEz20NkIElWA6vb6pNJvj3K/kziGODvR92JIZvrY3R8s9+MjDF/OOwz7Nd0xvdL+9sw20NkJ3Bc3/qSVvsZVbUOWDdTnTpQSbZV1dio+zFMc32Mjm/2m+tjHNb4ZvszkduAZUmOT3IYcA6wacR9kqRDxqy+EqmqZ5K8B9hCb4rv+qq6Z8TdkqRDxqwOEYCq2gxsHnU/pukFe6vtIJrrY3R8s99cH+NQxpeqGsZxJUmHgNn+TESSNEKGyIgleSDJ3UnuTLJt1P05GJKsT7IryTf7akcn2Zpke/u7YJR9nI79jO9DSXa29/HOJGeOso/TkeS4JDcluTfJPUne2+pz4j2cYnxz6T18SZJbk3yjjfH3W/34JLckGU/y2TYhaXrn8nbWaCV5ABirqjkzBz/JbwBPAhur6jWt9t+APVW1NskaYEFVXTLKfna1n/F9CHiyqv77KPt2MCQ5Fji2qr6e5GXA7cBZwL9nDryHU4zvbObOexjgiKp6MsmLgb8D3gu8H/hiVV2T5H8A36iqq6ZzLq9EdNBV1d8Ce/YprwQ2tOUN9P7Rzkr7Gd+cUVUPV9XX2/IPgPvofTvEnHgPpxjfnFE9T7bVF7dXAW8FPt/qB+U9NERGr4C/TnJ7+2T9XLWoqh5uy48Ai0bZmSF5T5K72u2uWXmrZ19JlgJvAG5hDr6H+4wP5tB7mGRekjuBXcBW4DvA41X1TGuyg4MQnobI6L25qk6k903EF7dbJXNa9e6hzrX7qFcBvwy8HngY+KPRdmf6kvw88AXgfVW1t3/bXHgPJxnfnHoPq+rHVfV6et/kcTLw6mGcxxAZsara2f7uAr5E782eix5t96In7knvGnF/DqqqerT9o/0J8BfM8vex3Uf/AvCpqvpiK8+Z93Cy8c2193BCVT0O3AS8CTgqycTnAyf9mqgDZYiMUJIj2oM9khwBLAe+OfVes9YmYFVbXgVcN8K+HHQT/3FtfptZ/D62h7JXA/dV1Uf6Ns2J93B/45tj7+HCJEe15cOBt9F79nMT8M7W7KC8h87OGqEkr6R39QG9bw/4dFVdPsIuHRRJPgO8hd63hj4KXAp8GbgWeAXwIHB2Vc3Kh9P7Gd9b6N0GKeAB4N19zw9mlSRvBv4PcDfwk1b+IL3nBrP+PZxifOcyd97D19J7cD6P3sXCtVV1WftvzjXA0cAdwLuq6qlpncsQkSR15e0sSVJnhogkqTNDRJLUmSEiSerMEJEkdWaISJI6M0QkSZ0ZIpKkzv4/2LyLCkd/AwYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.line_number.plot.hist();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "9aujM0Sa72NG",
        "outputId": "ff60f49c-5a7b-4d66-dbca-e5a944af4b7d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List of sentences (abstract text lines -> lists)\n",
        "train_sentences = train_df[\"text\"].tolist()\n",
        "val_sentences = val_df[\"text\"].tolist()\n",
        "test_sentences = test_df[\"text\"].tolist()\n",
        "len(train_sentences), len(val_sentences), len(test_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ia2ch3u_8CrC",
        "outputId": "249a203f-0040-4802-8eab-291b88c88bee"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(180040, 30212, 30135)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6V8HT4a8OX_",
        "outputId": "930719e8-1199-4c52-bfc0-c15992657390"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
              " 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
              " 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
              " 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
              " 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
              " 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
              " 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
              " 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
              " 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
              " 'these differences remained significant at @ weeks .',\n",
              " 'the outcome measures in rheumatology clinical trials-osteoarthritis research society international responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .',\n",
              " 'low-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee oa ( clinicaltrials.gov identifier nct@ ) .',\n",
              " 'emotional eating is associated with overeating and the development of obesity .',\n",
              " 'yet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .',\n",
              " 'the aim of this study was to test if attention bias for food moderates the effect of self-reported emotional eating during sad mood ( vs neutral mood ) on actual food intake .',\n",
              " 'it was expected that emotional eating is predictive of elevated attention for food and higher food intake after an experimentally induced sad mood and that attentional maintenance on food predicts food intake during a sad versus a neutral mood .',\n",
              " 'participants ( n = @ ) were randomly assigned to one of the two experimental mood induction conditions ( sad/neutral ) .',\n",
              " 'attentional biases for high caloric foods were measured by eye tracking during a visual probe task with pictorial food and neutral stimuli .',\n",
              " 'self-reported emotional eating was assessed with the dutch eating behavior questionnaire ( debq ) and ad libitum food intake was tested by a disguised food offer .',\n",
              " 'hierarchical multivariate regression modeling showed that self-reported emotional eating did not account for changes in attention allocation for food or food intake in either condition .']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing for the modelling "
      ],
      "metadata": {
        "id": "_-gGcC0b_HXF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "one_hot_encoder = OneHotEncoder(sparse=False)\n",
        "train_labels_one_hot = one_hot_encoder.fit_transform(train_df[\"target\"].to_numpy().reshape(-1, 1))\n",
        "val_labels_one_hot = one_hot_encoder.transform(val_df[\"target\"].to_numpy().reshape(-1, 1))\n",
        "test_labels_one_hot = one_hot_encoder.transform(test_df[\"target\"].to_numpy().reshape(-1, 1))"
      ],
      "metadata": {
        "id": "m1xPlRMc_UCT"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels_one_hot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2yHpXjEA4Ox",
        "outputId": "5434fbe8-6899-478b-cc8e-041497d42b03"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Labelling\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels_encoded = label_encoder.fit_transform(train_df[\"target\"].to_numpy())\n",
        "val_labels_encoded = label_encoder.transform(val_df[\"target\"].to_numpy())\n",
        "test_labels_encoded = label_encoder.transform(test_df[\"target\"].to_numpy())"
      ],
      "metadata": {
        "id": "vX3HUoF5BCYE"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels_encoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLUKrkfeCSkW",
        "outputId": "bc9003eb-1c0c-4579-914b-0832f9a3a6f8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 2, 2, ..., 4, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the classes \n",
        "num_classes = len(label_encoder.classes_)\n",
        "class_names = label_encoder.classes_\n",
        "num_classes, class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRZkLYj5CWRL",
        "outputId": "9e0f6ae7-b94b-4520-cc3b-25143d5de9ca"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, array(['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS'],\n",
              "       dtype=object))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modellling"
      ],
      "metadata": {
        "id": "JCz8bulnCtUc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model_1"
      ],
      "metadata": {
        "id": "4A0WsFG8CyyW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model_1\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "model_1 = Pipeline([\n",
        "                    (\"tf-idf\", TfidfVectorizer()),\n",
        "                    (\"clf\", MultinomialNB())\n",
        "])\n",
        "\n",
        "model_1.fit(X=train_sentences,\n",
        "            y=train_labels_encoded)\n",
        "\n",
        "model_1.score(X=val_sentences,\n",
        "              y=val_labels_encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2vpt7MsC3CT",
        "outputId": "98a236cc-05c7-4c84-f3ad-a7e3aaaab819"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7218323844829869"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction on model_1\n",
        "model_1_preds = model_1.predict(val_sentences)\n",
        "model_1_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6U5fsL9D98A",
        "outputId": "0f05b61d-c30f-44a6-9101-8b6388d45303"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 1, 3, ..., 4, 4, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation \n",
        "model_1_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                  y_pred=model_1_preds)\n",
        "model_1_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w52SI9K4Eiwd",
        "outputId": "c29c01a8-37f8-4a90-caff-5b63766d1967"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 72.1832384482987,\n",
              " 'f1': 0.6989250353450294,\n",
              " 'precision': 0.7186466952323352,\n",
              " 'recall': 0.7218323844829869}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model_2 (with sequencing)"
      ],
      "metadata": {
        "id": "bkMEnDJZF5L2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model_2 data preprocessing\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# average length of sentence\n",
        "sentence_len = [len(sentence.split()) for sentence in train_sentences]\n",
        "avg_sentence_len = np.mean(sentence_len)\n",
        "avg_sentence_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hl8tIxGMGAsw",
        "outputId": "365053c5-7f76-412f-a9e4-cada777862ea"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26.338269273494777"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(sentence_len, bins=10);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "rlcxMwdAGwvA",
        "outputId": "e6013cff-0207-4e1f-ec6c-9aaaf09b1968"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check the % of sentences length between 0-50 & max sentence length\n",
        "output_seq_len = int(np.percentile(sentence_len, 95))\n",
        "output_seq_len, max(sentence_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vY1_UbTG6c9",
        "outputId": "3abddc6d-a5fa-41bf-cf3b-3c3241e314b5"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(55, 296)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Vectorization"
      ],
      "metadata": {
        "id": "GvtJEpFQHx4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Section 3.2 states that the vocabulary size is 68,000 - https://arxiv.org/pdf/1710.06071.pdf\n",
        "max_tokens = 68000 "
      ],
      "metadata": {
        "id": "flq878KaH8sa"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# text vectorization\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "text_vectorizer = TextVectorization(max_tokens=max_tokens,\n",
        "                                    output_sequence_length=55)\n",
        "# adapting text vectorizer to training sentences\n",
        "text_vectorizer.adapt(train_sentences)\n",
        "\n",
        "# testing the text vectorizer\n",
        "import random \n",
        "target_sentence = random.choice(train_sentences)\n",
        "print(f\"Text:\\n{target_sentence}\")\n",
        "print(f\"\\nLength of text: {len(target_sentence.split())}\")\n",
        "print(f\"\\nVectorized text:\\n{text_vectorizer([target_sentence])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tm2-BY0yQKZF",
        "outputId": "740c5e92-575e-4e03-d6b9-b450f1e0282f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text:\n",
            "there were no significant differences in demographic characteristics , asa classification , length of surgery , estimated blood loss and the ci during surgery .\n",
            "\n",
            "Length of text: 25\n",
            "\n",
            "Vectorized text:\n",
            "[[  61    9   33   37  102    5 1224  395 2128 1911  523    4  115  597\n",
            "   107  264    3    2   50   52  115    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of words in the training vocabulary\n",
        "rct_20k_text_vocab = text_vectorizer.get_vocabulary()\n",
        "print(f\"Total number of words in vocabulary: {len(rct_20k_text_vocab)}\"),\n",
        "print(f\"Most common words: {rct_20k_text_vocab[:5]}\")\n",
        "print(f\"Least common words: {rct_20k_text_vocab[-5:]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uFCGlvbR9OG",
        "outputId": "3a68c5c6-a815-4903-da57-58408a2cfe7c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of words in vocabulary: 64841\n",
            "Most common words: ['', '[UNK]', 'the', 'and', 'of']\n",
            "Least common words: ['aainduced', 'aaigroup', 'aachener', 'aachen', 'aaacp']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration \n",
        "text_vectorizer.get_config()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYF2APNjTLs2",
        "outputId": "603db33d-65a9-4365-e795-ab7a19513c0c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_input_shape': (None,),\n",
              " 'dtype': 'string',\n",
              " 'idf_weights': None,\n",
              " 'max_tokens': 68000,\n",
              " 'name': 'text_vectorization',\n",
              " 'ngrams': None,\n",
              " 'output_mode': 'int',\n",
              " 'output_sequence_length': 55,\n",
              " 'pad_to_max_tokens': False,\n",
              " 'ragged': False,\n",
              " 'sparse': False,\n",
              " 'split': 'whitespace',\n",
              " 'standardize': 'lower_and_strip_punctuation',\n",
              " 'trainable': True,\n",
              " 'vocabulary': None}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Embedding token layer\n",
        "token_embed = layers.Embedding(input_dim=len(rct_20k_text_vocab),\n",
        "                              output_dim=128,\n",
        "                              mask_zero=True,\n",
        "                              name=\"token_embedding\")\n",
        "\n",
        "# View embedded token layer\n",
        "print(f\"before vectorization:\\n{target_sentence}\\n\")\n",
        "vectorized__sentence = text_vectorizer([target_sentence])\n",
        "print(f\"after vectorization:\\n{vectorized__sentence}\\n\")\n",
        "embedded_sentence = token_embed(vectorized__sentence)\n",
        "print(f\"after embedding:\\n{embedded_sentence}\\n\")\n",
        "print(f\"shape after embedding: {embedded_sentence.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAQmPECiTVH9",
        "outputId": "f2db65f4-29a2-4f11-b3d1-23bf885ab195"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before vectorization:\n",
            "there were no significant differences in demographic characteristics , asa classification , length of surgery , estimated blood loss and the ci during surgery .\n",
            "\n",
            "after vectorization:\n",
            "[[  61    9   33   37  102    5 1224  395 2128 1911  523    4  115  597\n",
            "   107  264    3    2   50   52  115    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0]]\n",
            "\n",
            "after embedding:\n",
            "[[[ 0.01341379  0.04481438  0.01588679 ... -0.0117395  -0.00790412\n",
            "    0.01852873]\n",
            "  [ 0.02011022 -0.04406952  0.01372776 ...  0.03429624  0.02385049\n",
            "   -0.02464448]\n",
            "  [-0.01025734 -0.00888624  0.03172824 ...  0.0184494   0.03616465\n",
            "   -0.01937068]\n",
            "  ...\n",
            "  [ 0.04866513  0.01006328  0.03525047 ... -0.0032981   0.02187962\n",
            "    0.04047606]\n",
            "  [ 0.04866513  0.01006328  0.03525047 ... -0.0032981   0.02187962\n",
            "    0.04047606]\n",
            "  [ 0.04866513  0.01006328  0.03525047 ... -0.0032981   0.02187962\n",
            "    0.04047606]]]\n",
            "\n",
            "shape after embedding: (1, 55, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Tensorflow dataset API for fast processing\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences, train_labels_one_hot))\n",
        "valid_dataset = tf.data.Dataset.from_tensor_slices((val_sentences, val_labels_one_hot))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_sentences, test_labels_one_hot))\n",
        "train_dataset"
      ],
      "metadata": {
        "id": "n0kzy2EKVJ2_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ae388e2-098d-4f16-9864-6b5517f1afa0"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: ((), (5,)), types: (tf.string, tf.float64)>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the data into batches\n",
        "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "valid_dataset = valid_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNe8Bg9YI1jN",
        "outputId": "5aa931fb-a1cb-4340-ff0c-3f62d72f7e90"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((None,), (None, 5)), types: (tf.string, tf.float64)>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelling Conv1D model_2\n",
        "\n",
        "inputs= layers.Input(shape=(1,), dtype=tf.string)\n",
        "text_vectors = text_vectorizer(inputs)\n",
        "token_embeddings = token_embed(text_vectors)\n",
        "x = layers.Conv1D(64, kernel_size=5, padding=\"same\", activation=\"relu\")(token_embeddings)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "model_2 = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "model_2.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "model_2_history = model_2.fit(train_dataset,\n",
        "                              steps_per_epoch=int(0.1 * len(train_dataset)),\n",
        "                              epochs=3,\n",
        "                              validation_data=valid_dataset,\n",
        "                              validation_steps=int(0.1 * len(valid_dataset)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rg0oLAf4JdWn",
        "outputId": "24b4022c-145a-41dc-e9a0-bd16d0504bf7"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "562/562 [==============================] - 52s 91ms/step - loss: 0.9259 - accuracy: 0.6360 - val_loss: 0.6910 - val_accuracy: 0.7377\n",
            "Epoch 2/3\n",
            "562/562 [==============================] - 51s 91ms/step - loss: 0.6649 - accuracy: 0.7540 - val_loss: 0.6448 - val_accuracy: 0.7673\n",
            "Epoch 3/3\n",
            "562/562 [==============================] - 51s 91ms/step - loss: 0.6213 - accuracy: 0.7747 - val_loss: 0.5947 - val_accuracy: 0.7846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6PN_DzCLIjd",
        "outputId": "8392a8c1-ea9e-4958-9fbc-b3e614a0873a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 55)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " token_embedding (Embedding)  (None, 55, 128)          8299648   \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 55, 64)            41024     \n",
            "                                                                 \n",
            " global_average_pooling1d_1   (None, 64)               0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dense (Dense)               (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,340,997\n",
            "Trainable params: 8,340,997\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "model_2.evaluate(valid_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmQ7FzkVMCMh",
        "outputId": "407bd267-25a5-40ea-cb08-dee390cf0dd7"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "945/945 [==============================] - 4s 4ms/step - loss: 0.5988 - accuracy: 0.7864\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5987774729728699, 0.7864093780517578]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "model_2_pred_probs = model_2.predict(valid_dataset)\n",
        "model_2_pred_probs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gnFLbCYMObh",
        "outputId": "cc183aae-b8d7-46bd-9df2-fa64f0226e95"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.4302985e-01, 1.8588908e-01, 8.4681794e-02, 2.4652679e-01,\n",
              "        3.9872400e-02],\n",
              "       [4.1563219e-01, 3.1297153e-01, 1.0353863e-02, 2.5301781e-01,\n",
              "        8.0245230e-03],\n",
              "       [1.6473052e-01, 1.0862859e-02, 3.4790861e-03, 8.2086515e-01,\n",
              "        6.2383835e-05],\n",
              "       ...,\n",
              "       [6.5485783e-06, 5.9043226e-04, 1.2139605e-03, 1.8601128e-06,\n",
              "        9.9818724e-01],\n",
              "       [5.9975449e-02, 5.5618078e-01, 6.5442555e-02, 6.8651684e-02,\n",
              "        2.4974959e-01],\n",
              "       [2.1597144e-01, 5.9042013e-01, 5.7634220e-02, 7.8712925e-02,\n",
              "        5.7261359e-02]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Turning the prediction probabilities into classes\n",
        "model_2_preds = tf.argmax(model_2_pred_probs, axis=1)\n",
        "model_2_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awfCkxO6MdCx",
        "outputId": "8572c426-060c-497c-de86-65771a4887ad"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 0, 3, ..., 4, 1, 1])>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the results \n",
        "model_2_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                    y_pred=model_2_preds)\n",
        "model_2_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u24eJPbeM0d9",
        "outputId": "abb514f8-dca3-4ba8-c9d0-68696a8b2e7b"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.64093737587714,\n",
              " 'f1': 0.7841784379669267,\n",
              " 'precision': 0.7831568831969138,\n",
              " 'recall': 0.7864093737587714}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model_3 using feature extraction"
      ],
      "metadata": {
        "id": "FrNvx0_ONNlP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pretrained model universal-sentence-encoder from hub\n",
        "import tensorflow_hub as hub\n",
        "tf_hub_embedding_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        trainable=False,\n",
        "                                        name=\"universal_sentence_encoder\")\n",
        "\n",
        "# Testing \n",
        "sample_sentence_for_training = random.choice(train_sentences)\n",
        "print(f\"Sample training sentence:\\n{sample_sentence_for_training}\\n\")\n",
        "use_embedded_sentence = tf_hub_embedding_layer([sample_sentence_for_training])\n",
        "print(f\"Sample sentence after embedding:\\n{use_embedded_sentence[0][:30]} (truncated_output)...\\n\")\n",
        "print(f\"Length of the embedded sentence:\\n{len(use_embedded_sentence[0])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CUqA1AMNYdS",
        "outputId": "91e2c004-94ac-48ed-b8f1-367257e6e918"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample training sentence:\n",
            "we undertook this study to determine whether oral magnesium supplementation modifies serum levels of high-sensitivity c-reactive protein ( hscrp ) in apparently healthy subjects with prediabetes and hypomagnesemia .\n",
            "\n",
            "Sample sentence after embedding:\n",
            "[-0.02839779  0.0260007  -0.03962677 -0.05834273  0.0263      0.0061941\n",
            "  0.06408999 -0.02839705  0.04209505  0.04772086  0.08197236  0.06480646\n",
            "  0.05788472  0.06544226 -0.08403166 -0.0343082  -0.08778667  0.02648667\n",
            "  0.05623003 -0.06792317  0.01473383  0.02120501 -0.03598375  0.04757003\n",
            "  0.00622224  0.0099448   0.04835591 -0.04160522 -0.0379659   0.00775846] (truncated_output)...\n",
            "\n",
            "Length of the embedded sentence:\n",
            "512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelling model_3\n",
        "inputs = layers.Input(shape=[], dtype=tf.string)\n",
        "pretrained_embedding = tf_hub_embedding_layer(inputs)\n",
        "x = layers.Dense(128, activation=\"relu\")(pretrained_embedding)\n",
        "outputs = layers.Dense(5, activation=\"softmax\")(x)\n",
        "model_3 = tf.keras.Model(inputs=inputs,\n",
        "                         outputs=outputs)\n",
        "model_3.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "model_3.fit(train_dataset,\n",
        "            epochs=3,\n",
        "            steps_per_epoch=int(0.1 * len(train_dataset)),\n",
        "            validation_data=valid_dataset,\n",
        "            validation_steps=int(0.1 * len(valid_dataset)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0auhibLPYdI",
        "outputId": "fea9fe97-7bc5-467c-9e3a-c2cd7e5d2d15"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "562/562 [==============================] - 8s 11ms/step - loss: 0.9129 - accuracy: 0.6534 - val_loss: 0.7975 - val_accuracy: 0.6885\n",
            "Epoch 2/3\n",
            "562/562 [==============================] - 6s 10ms/step - loss: 0.7689 - accuracy: 0.7012 - val_loss: 0.7557 - val_accuracy: 0.7038\n",
            "Epoch 3/3\n",
            "562/562 [==============================] - 6s 10ms/step - loss: 0.7524 - accuracy: 0.7122 - val_loss: 0.7403 - val_accuracy: 0.7128\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1bcedf8510>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRGNsCb6R_CQ",
        "outputId": "d785da90-629b-40e4-c89c-48852b6a479b"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None,)]                 0         \n",
            "                                                                 \n",
            " universal_sentence_encoder   (None, 512)              256797824 \n",
            " (KerasLayer)                                                    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               65664     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,864,133\n",
            "Trainable params: 66,309\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model_3\n",
        "model_3.evaluate(valid_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waZmi-ynSKHi",
        "outputId": "6d30428b-8811-4a44-d9ac-a6c0a3de2986"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "945/945 [==============================] - 8s 8ms/step - loss: 0.7415 - accuracy: 0.7135\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7414579391479492, 0.713458240032196]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions \n",
        "model_3_pred_probs = model_3.predict(valid_dataset)\n",
        "model_3_pred_probs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sX4jowPMSVnL",
        "outputId": "80433f1e-816a-46c1-9adb-8b525bb2f088"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.4507712e-01, 3.4393445e-01, 2.4809248e-03, 1.9900864e-01,\n",
              "        9.4988495e-03],\n",
              "       [3.4531966e-01, 5.0955242e-01, 3.2439879e-03, 1.3807851e-01,\n",
              "        3.8053989e-03],\n",
              "       [2.2812515e-01, 1.3852850e-01, 1.8403791e-02, 5.8045262e-01,\n",
              "        3.4489986e-02],\n",
              "       ...,\n",
              "       [1.5836151e-03, 5.7425778e-03, 6.4713754e-02, 8.6891872e-04,\n",
              "        9.2709112e-01],\n",
              "       [4.8293928e-03, 4.9722888e-02, 2.0999403e-01, 1.8755810e-03,\n",
              "        7.3357809e-01],\n",
              "       [1.5188809e-01, 2.8464070e-01, 5.1179641e-01, 6.4735729e-03,\n",
              "        4.5201238e-02]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the pred_probs to classes\n",
        "model_3_preds = tf.argmax(model_3_pred_probs, axis=1)\n",
        "model_3_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsJDtbB5SiWa",
        "outputId": "18293a7b-bf2b-432c-97ae-64f2bf59f70c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 1, 3, ..., 4, 4, 2])>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the results\n",
        "model_3_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                    y_pred=model_3_preds)\n",
        "model_3_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsqM_CmUSxXz",
        "outputId": "ba6d4c82-6806-49d4-bf77-576fd2295b9b"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 71.34582285184695,\n",
              " 'f1': 0.7102243996494003,\n",
              " 'precision': 0.7136256933594347,\n",
              " 'recall': 0.7134582285184695}"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# model_4 with character embeddings"
      ],
      "metadata": {
        "id": "1gmVF8QeTBkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for character splitting\n",
        "def split_character(text):\n",
        "  return \" \".join(list(text))\n",
        "\n",
        "split_character(sample_sentence_for_training)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "lCDKdUmZTPFu",
        "outputId": "c2d5b8d7-0b75-4a8b-d5d9-3a6ad3bb8a66"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'w e   u n d e r t o o k   t h i s   s t u d y   t o   d e t e r m i n e   w h e t h e r   o r a l   m a g n e s i u m   s u p p l e m e n t a t i o n   m o d i f i e s   s e r u m   l e v e l s   o f   h i g h - s e n s i t i v i t y   c - r e a c t i v e   p r o t e i n   (   h s c r p   )   i n   a p p a r e n t l y   h e a l t h y   s u b j e c t s   w i t h   p r e d i a b e t e s   a n d   h y p o m a g n e s e m i a   .'"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split the sequence \n",
        "train_char = [split_character(sentence) for sentence in train_sentences]\n",
        "val_char = [split_character(sentence) for sentence in val_sentences]\n",
        "test_char = [split_character(sentence) for sentence in test_sentences]\n",
        "print(train_char[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wz0MVrtRTqWd",
        "outputId": "d2d011b0-5a47-40e3-98ac-1aea4fc37b33"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t o   i n v e s t i g a t e   t h e   e f f i c a c y   o f   @   w e e k s   o f   d a i l y   l o w - d o s e   o r a l   p r e d n i s o l o n e   i n   i m p r o v i n g   p a i n   ,   m o b i l i t y   ,   a n d   s y s t e m i c   l o w - g r a d e   i n f l a m m a t i o n   i n   t h e   s h o r t   t e r m   a n d   w h e t h e r   t h e   e f f e c t   w o u l d   b e   s u s t a i n e d   a t   @   w e e k s   i n   o l d e r   a d u l t s   w i t h   m o d e r a t e   t o   s e v e r e   k n e e   o s t e o a r t h r i t i s   (   o a   )   .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Average length of the character\n",
        "character_length = [len(sentence) for sentence in train_sentences]\n",
        "mean_character_length = np.mean(character_length)\n",
        "mean_character_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74WL9rjmUYuk",
        "outputId": "ceafddeb-b8c6-4afa-dcbe-7711d8d1b4d1"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "149.3662574983337"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(character_length, bins=10);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "Q-NFspvNUxzJ",
        "outputId": "105f7070-5614-4cd0-dc28-ac149c0c76ff"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the plot, we can observe that most of the sequences are between 0-200 characters long."
      ],
      "metadata": {
        "id": "gPoTKROlU4A2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for 95% of character length of sequences\n",
        "output_seq_character_length = int(np.percentile(character_length, 95))\n",
        "output_seq_character_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwnweXyiVOxY",
        "outputId": "0cb4f5c2-312c-4f6d-ff21-19c5f78d2c08"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "290"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing and character embeddings\n",
        "import string\n",
        "alphabet = string.ascii_lowercase + string.digits + string.punctuation\n",
        "alphabet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Q2J_YsdgVqJu",
        "outputId": "973124bd-7a36-4a7f-e67a-538c93d8da89"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'abcdefghijklmnopqrstuvwxyz0123456789!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizing the character\n",
        "NUM_CHAR_TOKENS = len(alphabet) + 2\n",
        "character_vectorizer = TextVectorization(max_tokens=NUM_CHAR_TOKENS,\n",
        "                                         output_sequence_length=output_seq_character_length,\n",
        "                                         standardize=\"lower_and_strip_punctuation\",\n",
        "                                         name=\"character_vectorizer\")\n",
        "character_vectorizer.adapt(train_char)\n",
        "\n",
        "# Sample of character vocabulary\n",
        "character_vocab = character_vectorizer.get_vocabulary()\n",
        "print(f\"Total number of unique characters: {len(character_vocab)}\")\n",
        "print(f\"10 most common characters: {character_vocab[:10]}\")\n",
        "print(f\"10 least common characters: {character_vocab[-10:]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAoLqbnqWHTd",
        "outputId": "78805912-2e8d-4237-f517-6438e5ecf504"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of unique characters: 28\n",
            "10 most common characters: ['', '[UNK]', 'e', 't', 'i', 'a', 'n', 'o', 'r', 's']\n",
            "10 least common characters: ['g', 'y', 'w', 'v', 'b', 'k', 'x', 'z', 'q', 'j']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample of character vectorizer\n",
        "import random\n",
        "sample_train_character = random.choice(train_char)\n",
        "print(f\" Text (in characters):\\n{sample_train_character}\")\n",
        "print(f\"\\nCharacter length: {len(sample_train_character.split())}\")\n",
        "vectorized__character = character_vectorizer([sample_train_character])\n",
        "print(f\"\\nCharacter Vectorized:\\n{vectorized__character}\")\n",
        "print(f\"\\nVectorized character length: {len(vectorized__character[0])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e68OOa3GX2sx",
        "outputId": "2b3e7d37-8763-47c4-9391-2adad64c103e"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Text (in characters):\n",
            "g i v e n   t h e   m u l t i p l e   d e m a n d s   m o t h e r s   f a c e   ,   a   f a i l u r e   t o   r e c o g n i s e   t h e i r   u n i q u e   n e e d s   i s   l i k e l y   t o   c o n t r i b u t e   t o   i n t e r g e n e r a t i o n a l   l e g a c i e s   o f   h o m e l e s s n e s s   a n d   m e n t a l   h e a l t h   p r o b l e m s   .\n",
            "\n",
            "Character length: 155\n",
            "\n",
            "Character Vectorized:\n",
            "[[18  4 21  2  6  3 13  2 15 16 12  3  4 14 12  2 10  2 15  5  6 10  9 15\n",
            "   7  3 13  2  8  9 17  5 11  2  5 17  5  4 12 16  8  2  3  7  8  2 11  7\n",
            "  18  6  4  9  2  3 13  2  4  8 16  6  4 26 16  2  6  2  2 10  9  4  9 12\n",
            "   4 23  2 12 19  3  7 11  7  6  3  8  4 22 16  3  2  3  7  4  6  3  2  8\n",
            "  18  2  6  2  8  5  3  4  7  6  5 12 12  2 18  5 11  4  2  9  7 17 13  7\n",
            "  15  2 12  2  9  9  6  2  9  9  5  6 10 15  2  6  3  5 12 13  2  5 12  3\n",
            "  13 14  8  7 22 12  2 15  9  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0]]\n",
            "\n",
            "Vectorized character length: 290\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Character embedding layer\n",
        "character_embed = layers.Embedding(input_dim=NUM_CHAR_TOKENS,\n",
        "                                   output_dim=25,\n",
        "                                   mask_zero=False,\n",
        "                                   name=\"character_embed\")\n",
        "\n",
        "# Sample\n",
        "print(f\"Character text before embeddings:\\n{sample_train_character}\\n\")\n",
        "character_embed_example = character_embed(character_vectorizer([sample_train_character]))\n",
        "print(f\"Embedded characters:\\n{character_embed_example}\\n\")\n",
        "print(f\"Shape of embedded character: {character_embed_example.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRrNfFJ_Zyeo",
        "outputId": "00ab9ccf-0e0d-4184-f28c-6f4755faf63c"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Character text before embeddings:\n",
            "g i v e n   t h e   m u l t i p l e   d e m a n d s   m o t h e r s   f a c e   ,   a   f a i l u r e   t o   r e c o g n i s e   t h e i r   u n i q u e   n e e d s   i s   l i k e l y   t o   c o n t r i b u t e   t o   i n t e r g e n e r a t i o n a l   l e g a c i e s   o f   h o m e l e s s n e s s   a n d   m e n t a l   h e a l t h   p r o b l e m s   .\n",
            "\n",
            "Embedded characters:\n",
            "[[[-0.00138418  0.00261258 -0.03166033 ...  0.00872849  0.03257681\n",
            "   -0.00372161]\n",
            "  [-0.04241898  0.04173816 -0.02953169 ... -0.01979643  0.03432314\n",
            "    0.04573176]\n",
            "  [-0.04287347  0.01445727 -0.03405704 ...  0.04374883 -0.02649885\n",
            "    0.00600332]\n",
            "  ...\n",
            "  [-0.03154651 -0.0190884  -0.02809893 ...  0.0309983  -0.00087031\n",
            "    0.00425646]\n",
            "  [-0.03154651 -0.0190884  -0.02809893 ...  0.0309983  -0.00087031\n",
            "    0.00425646]\n",
            "  [-0.03154651 -0.0190884  -0.02809893 ...  0.0309983  -0.00087031\n",
            "    0.00425646]]]\n",
            "\n",
            "Shape of embedded character: (1, 290, 25)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelling model_4 with Conv1D\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "character_vectors = character_vectorizer(inputs)\n",
        "character_embeddings = character_embed(character_vectors)\n",
        "x = layers.Conv1D(63, kernel_size=5, padding=\"same\", activation=\"relu\")(character_embeddings)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "model_4 = tf.keras.Model(inputs=inputs,\n",
        "                         outputs=outputs,\n",
        "                         name=\"model_4_conv1D_character_embedding\")\n",
        "model_4.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Character dataset\n",
        "train_character_dataset = tf.data.Dataset.from_tensor_slices((train_char, train_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "val_character_dataset = tf.data.Dataset.from_tensor_slices((val_char, val_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "model_4_history = model_4.fit(train_character_dataset,\n",
        "                              epochs=3,\n",
        "                              steps_per_epoch=int(0.1 * len(train_character_dataset)),\n",
        "                              validation_data=val_character_dataset,\n",
        "                              validation_steps=int(0.1 * len(val_character_dataset)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iq1zFCxnbIio",
        "outputId": "e8808569-d0b1-4bc0-c179-42e63e65fce9"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "562/562 [==============================] - 29s 50ms/step - loss: 1.2735 - accuracy: 0.4867 - val_loss: 1.0473 - val_accuracy: 0.5818\n",
            "Epoch 2/3\n",
            "562/562 [==============================] - 26s 46ms/step - loss: 1.0079 - accuracy: 0.5969 - val_loss: 0.9446 - val_accuracy: 0.6263\n",
            "Epoch 3/3\n",
            "562/562 [==============================] - 30s 53ms/step - loss: 0.9309 - accuracy: 0.6327 - val_loss: 0.8737 - val_accuracy: 0.6609\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_4.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jb9oYWOeduEf",
        "outputId": "ee50a7a9-0c09-47a2-db29-6978c9830380"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4_conv1D_character_embedding\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " character_vectorizer (TextV  (None, 290)              0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " character_embed (Embedding)  (None, 290, 25)          1750      \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 290, 63)           7938      \n",
            "                                                                 \n",
            " global_max_pooling1d_1 (Glo  (None, 63)               0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 5)                 320       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,008\n",
            "Trainable params: 10,008\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model_4 evaluation\n",
        "model_4.evaluate(val_character_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEPQWPz3efVD",
        "outputId": "07f6fb5a-ff45-438d-fb7f-d601fed9d629"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "945/945 [==============================] - 20s 21ms/step - loss: 0.8916 - accuracy: 0.6517\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.891582190990448, 0.6516947150230408]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "model_4_pred_probs = model_4.predict(val_character_dataset)\n",
        "# Predictions to classes\n",
        "model_4_preds = tf.argmax(model_4_pred_probs, axis=1)\n",
        "# Results\n",
        "model_4_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                    y_pred=model_4_preds)\n",
        "model_4_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qa64jOuefKOK",
        "outputId": "7db8b371-3d95-41e9-df02-a1fea8450144"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 65.16946908513174,\n",
              " 'f1': 0.6424524702542843,\n",
              " 'precision': 0.6452761439759128,\n",
              " 'recall': 0.6516946908513174}"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not good enough at 65% accuracy, compared to model_1, model_2 & model_3."
      ],
      "metadata": {
        "id": "Zs8Jc3OwgIkh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# model_5 with pretrained tokens and character embeddings"
      ],
      "metadata": {
        "id": "LJZOTdedgW94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokens inputs\n",
        "token_inputs = layers.Input(shape=[], dtype=tf.string, name=\"token_input\")\n",
        "token_embeddings = tf_hub_embedding_layer(token_inputs)\n",
        "token_output = layers.Dense(128, activation=\"relu\")(token_embeddings)\n",
        "token_model = tf.keras.Model(inputs=token_inputs,\n",
        "                             outputs=token_output)\n",
        "# Character inputs\n",
        "character_inputs = layers.Input(shape=(1,), dtype=tf.string, name=\"character_input\")\n",
        "character_vectors = character_vectorizer(character_inputs)\n",
        "character_embeddings = character_embed(character_vectors)\n",
        "character_biLSTM = layers.Bidirectional(layers.LSTM(25))(character_embeddings)\n",
        "character_model = tf.keras.Model(inputs=character_inputs,\n",
        "                                 outputs=character_biLSTM)\n",
        "# token & character concatenation \n",
        "token_character_concat = layers.Concatenate(name=\"token_character_hybrid\")([token_model.output,\n",
        "                                                                            character_model.output])\n",
        "# Output layers\n",
        "combined_dropout = layers.Dropout(0.5)(token_character_concat)\n",
        "combined_dense = layers.Dense(200, activation=\"relu\")(combined_dropout)\n",
        "final_dropout = layers.Dropout(0.5)(combined_dense)\n",
        "output_layer = layers.Dense(num_classes, activation=\"softmax\")(final_dropout)\n",
        "\n",
        "model_5 = tf.keras.Model(inputs=[token_model.input, character_model.input],\n",
        "                         outputs=output_layer,\n",
        "                         name=\"model_5_hybrid\")\n",
        "model_5.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Combining both of the training dataset & batching\n",
        "train_character_token_data = tf.data.Dataset.from_tensor_slices((train_sentences, train_char))\n",
        "train_character_token_labels = tf.data.Dataset.from_tensor_slices(train_labels_one_hot)\n",
        "train_character_token_dataset = tf.data.Dataset.zip((train_character_token_data, train_character_token_labels))\n",
        "train_character_token_dataset = train_character_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Combining both of the validation dataset & batching\n",
        "val_character_token_data = tf.data.Dataset.from_tensor_slices((val_sentences, val_char))\n",
        "val_character_token_labels = tf.data.Dataset.from_tensor_slices(val_labels_one_hot)\n",
        "val_character_token_dataset = tf.data.Dataset.zip((val_character_token_data, val_character_token_labels))\n",
        "val_character_token_dataset = val_character_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Fit\n",
        "model_5_history = model_5.fit(train_character_token_dataset,                           \n",
        "                              steps_per_epoch=int(0.1 * len(train_character_token_dataset)),\n",
        "                              epochs=3,\n",
        "                              validation_data=val_character_token_dataset,\n",
        "                              validation_steps=int(0.1 * len(val_character_token_dataset)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SK8rkO3glWp",
        "outputId": "13e468b9-0df8-46ab-ff0d-43a37203ee0f"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "562/562 [==============================] - 119s 206ms/step - loss: 0.9541 - accuracy: 0.6224 - val_loss: 0.7769 - val_accuracy: 0.6958\n",
            "Epoch 2/3\n",
            "562/562 [==============================] - 98s 174ms/step - loss: 0.7908 - accuracy: 0.6962 - val_loss: 0.7098 - val_accuracy: 0.7304\n",
            "Epoch 3/3\n",
            "562/562 [==============================] - 96s 171ms/step - loss: 0.7685 - accuracy: 0.7074 - val_loss: 0.6889 - val_accuracy: 0.7437\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_5.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVi6YtEIpTCe",
        "outputId": "9c9b34ec-f861-4980-d8c3-7969d63a444f"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5_hybrid\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " character_input (InputLayer)   [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " token_input (InputLayer)       [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " character_vectorizer (TextVect  (None, 290)         0           ['character_input[0][0]']        \n",
            " orization)                                                                                       \n",
            "                                                                                                  \n",
            " universal_sentence_encoder (Ke  (None, 512)         256797824   ['token_input[0][0]']            \n",
            " rasLayer)                                                                                        \n",
            "                                                                                                  \n",
            " character_embed (Embedding)    (None, 290, 25)      1750        ['character_vectorizer[6][0]']   \n",
            "                                                                                                  \n",
            " dense_16 (Dense)               (None, 128)          65664       ['universal_sentence_encoder[7][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " bidirectional_3 (Bidirectional  (None, 50)          10200       ['character_embed[6][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " token_character_hybrid (Concat  (None, 178)         0           ['dense_16[0][0]',               \n",
            " enate)                                                           'bidirectional_3[0][0]']        \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)            (None, 178)          0           ['token_character_hybrid[0][0]'] \n",
            "                                                                                                  \n",
            " dense_17 (Dense)               (None, 200)          35800       ['dropout_6[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)            (None, 200)          0           ['dense_17[0][0]']               \n",
            "                                                                                                  \n",
            " dense_18 (Dense)               (None, 5)            1005        ['dropout_7[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 256,912,243\n",
            "Trainable params: 114,419\n",
            "Non-trainable params: 256,797,824\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model_5 evaluation\n",
        "model_5.evaluate(val_character_token_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyJJjn4YsswX",
        "outputId": "f81fe31d-298f-466b-9826-4d03890e0f9b"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "945/945 [==============================] - 34s 36ms/step - loss: 0.6920 - accuracy: 0.7376\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6920127272605896, 0.7375876903533936]"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model_5 predictions\n",
        "model_5_pred_probs = model_5.predict(val_character_token_dataset)\n",
        "model_5_preds = tf.argmax(model_5_pred_probs, axis=1)\n",
        "model_5_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                    y_pred=model_5_preds)\n",
        "model_5_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OayKaA3Rs68f",
        "outputId": "bc72feaa-6451-4afe-a2a8-5e351db330bd"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 73.75877134913279,\n",
              " 'f1': 0.7355227972040616,\n",
              " 'precision': 0.7387452160402411,\n",
              " 'recall': 0.7375877134913279}"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "model_5 performs better than model_4 "
      ],
      "metadata": {
        "id": "ia_CZHCYuEtp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# model_6 with transfer learning and positional embeddings"
      ],
      "metadata": {
        "id": "yvwernTtufoD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # EDA before modelling\n",
        " train_df[\"line_number\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WR--gjqupKK",
        "outputId": "72244407-629f-49f0-81f0-6d888b31cd22"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     15000\n",
              "1     15000\n",
              "2     15000\n",
              "3     15000\n",
              "4     14992\n",
              "5     14949\n",
              "6     14758\n",
              "7     14279\n",
              "8     13346\n",
              "9     11981\n",
              "10    10041\n",
              "11     7892\n",
              "12     5853\n",
              "13     4152\n",
              "14     2835\n",
              "15     1861\n",
              "16     1188\n",
              "17      751\n",
              "18      462\n",
              "19      286\n",
              "20      162\n",
              "21      101\n",
              "22       66\n",
              "23       33\n",
              "24       22\n",
              "25       14\n",
              "26        7\n",
              "27        4\n",
              "28        3\n",
              "29        1\n",
              "30        1\n",
              "Name: line_number, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.line_number.plot.hist();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "GnNywG80u5_d",
        "outputId": "87ded1cf-acab-4cdb-e54f-6bdebfe8133a"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One hot encoding\n",
        "train_line_numbers_one_hot = tf.one_hot(train_df[\"line_number\"].to_numpy(), depth=15)\n",
        "val_line_numbers_one_hot = tf.one_hot(val_df[\"line_number\"].to_numpy(), depth=15)\n",
        "test_line_numbers_one_hot = tf.one_hot(test_df[\"line_number\"].to_numpy(), depth=15)\n",
        "train_line_numbers_one_hot, train_line_numbers_one_hot[:25]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgvmqKdovAZ5",
        "outputId": "f9b2ff98-8163-4c5a-e56a-c120b760b45a"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(180040, 15), dtype=float32, numpy=\n",
              " array([[1., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 1., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 1., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(25, 15), dtype=float32, numpy=\n",
              " array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "       dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unique numbers of lines\n",
        "train_df[\"total_lines\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAZ0t8O5v2ra",
        "outputId": "3841dcf4-f34a-4121-bf99-7fcc26affa7d"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11    24468\n",
              "10    23639\n",
              "12    22113\n",
              "9     19400\n",
              "13    18438\n",
              "14    14610\n",
              "8     12285\n",
              "15    10768\n",
              "7      7464\n",
              "16     7429\n",
              "17     5202\n",
              "6      3353\n",
              "18     3344\n",
              "19     2480\n",
              "20     1281\n",
              "5      1146\n",
              "21      770\n",
              "22      759\n",
              "23      264\n",
              "4       215\n",
              "24      200\n",
              "25      182\n",
              "26       81\n",
              "28       58\n",
              "3        32\n",
              "30       31\n",
              "27       28\n",
              "Name: total_lines, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.total_lines.plot.hist();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "1g9b1HIGwDM1",
        "outputId": "f2906ab6-2c92-4d61-b6ce-2fc06a107878"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# total_lines value of 20 in %\n",
        "np.percentile(train_df.total_lines, 98)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_ncJOpYwJbN",
        "outputId": "140c8c95-2517-4efa-b82b-e299288f068f"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20.0"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One hot encoding the total_lines\n",
        "train_total_lines_one_hot = tf.one_hot(train_df[\"total_lines\"].to_numpy(), depth=20)\n",
        "val_total_lines_one_hot = tf.one_hot(val_df[\"total_lines\"].to_numpy(), depth=20)\n",
        "test_total_lines_one_hot = tf.one_hot(test_df[\"total_lines\"].to_numpy(), depth=20)\n",
        "train_total_lines_one_hot.shape, train_total_lines_one_hot[:15]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0V9CFWkdwhTF",
        "outputId": "7097c60f-941a-4cef-a14b-341cc05746aa"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([180040, 20]), <tf.Tensor: shape=(15, 20), dtype=float32, numpy=\n",
              " array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.]], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelling model_6\n",
        "\n",
        "# token\n",
        "token_inputs = layers.Input(shape=[], dtype=\"string\", name=\"token_inputs\")\n",
        "token_embeddings = tf.tf_hub_embedding_layer(token_inputs)\n",
        "token_outputs = layers.Dense(128, activation=\"relu\")(token_embeddings)\n",
        "token_model = tf.keras.Model(inputs=token_inputs,\n",
        "                             outputs=token_outputs)\n",
        "# character\n",
        "character_inputs = layers.Input(shape=(1,), dtype=\"string\", name=\"character_inputs\")\n",
        "character_vectors = character_vectorizer(character_inputs)\n",
        "character_embeddings = character_embed(character_vectors)\n",
        "character_biLSTM = layers.Bidirectional(layers.LSTM(32))(character_embeddings)\n",
        "character_model = tf.keras.Model(inputs=character_inputs,\n",
        "                                 outputs=character_biLSTM)\n",
        "# line numbers\n",
        "line_number_inputs = layers.Input(shape=(15,), dtype=tf.int32, name=\"line_number_input\")\n",
        "x = layers.Dense(32, activation=\"relu\")(line_number_inputs)\n",
        "line_number_model = tf.keras.Model(inputs=line_number_inputs,\n",
        "                                   outputs=x)\n",
        "# total lines\n",
        "total_lines_input = layers.Input(shape=(20,), dtype=tf.int32, name=\"total_lines_input\")\n",
        "y = layers.Dense(32, activation=\"relu\")(total_lines_inputs)\n",
        "total_lines_model = tf.keras.Model(inputs=total_lines_inputs,\n",
        "                                   outputs=y)\n",
        "# Concatenate token & character embeddings \n",
        "combined_embeddings = layers.Concatenate(name=\"token_character_hybrid_embedding\")([token_model.output,\n",
        "                                                                                   character_model.output])\n",
        "z = layers.Dense(256, activation=\"relu\")(combined_embeddings)\n",
        "z = layers.Dropout(0.5)(z)\n",
        "# Concatenate positional embeddings with token & character embeddings\n",
        "z = layers.Concatenate(name=\"token_character_positional_embedding\")([line_number_model.output,\n",
        "                                                                     total_line_model.output,\n",
        "                                                                     z])\n",
        "# Output layer\n",
        "output_layer = layers.Dense(5, activation=\"softmax\", name=\"output_layer\")(z)\n",
        "\n",
        "# model_6\n",
        "model_6 = tf.keras.Model(inputs=[line_number_model.input,\n",
        "                                 total_line_model.input,\n",
        "                                 token_model.input,\n",
        "                                 character_model.input],\n",
        "                         outputs=output_layer)\n",
        "\n",
        "model_6.compile(loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.2),\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# training & validation dataset for x, y, z\n",
        "train_pos_character_token_data = tf.data.Dataset.from_tensor_slices((train_line_numbers_one_hot,\n",
        "                                                                     train_total_lines_one_hot,\n",
        "                                                                     train_sentences,\n",
        "                                                                     train_char))\n",
        "train_pos_character_token_labels = tf.data.Dataset.from_tensor_slices((train_labels_one_hot)\n",
        "train_pos_character_token_dataset = tf.data.Dataset.zip((train_pos_character_token_data, train_pos_character_token_labels))\n",
        "train_pos_character_token_dataset = train_pos_character_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# validation_dataset\n",
        "val_pos_character_token_data = tf.data.Dataset.from_tensor_slices((val_line_numbers_one_hot,\n",
        "                                                                   val_total_lines_one_hot,\n",
        "                                                                   val_sentences,\n",
        "                                                                   val_char))\n",
        "val_pos_character_token_labels = tf.data.Dataset.from_tensor_slices(val_labels_one_hot)\n",
        "val_pos_character_token_dataset = tf.data.Dataset.zip((val_pos_character_token_data, val_pos_character_token_labels))\n",
        "val_pos_character_token_dataset = val_pos_character_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Fit \n",
        "model_6_history = model_6.fit(train_pos_character_token_dataset,\n",
        "                              steps_per_epoch=int(0.1 * len(train_pos_character_token_dataset)),\n",
        "                              epochs=3,\n",
        "                              validation_data=val_pos_character_token_dataset,\n",
        "                              validation_steps=int(0.1 * len(val_pos_character_token_dataset)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "fQ2SKwC5xarE",
        "outputId": "07e4c448-c79f-4df0-cbd2-aad185cb179f"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-95-6edc704ace3c>\"\u001b[0;36m, line \u001b[0;32m55\u001b[0m\n\u001b[0;31m    train_pos_character_token_dataset = tf.data.Dataset.zip((train_pos_character_token_data, train_pos_character_token_labels))\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mpojCiyv9NRb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}